{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises - Mastering Postgresql\n",
    "\n",
    "Here are the consolidated list of exercises covering all the key topics related to Postgresql to gain mastery over SQL.\n",
    "\n",
    "* Ability to use native utilities to load data.\n",
    "* Perform CRUD or DML Operations.\n",
    "* Writing basic SQL queries.\n",
    "* Creating Tables, Indexes and Constraints.\n",
    "* Create and Load data into Partitioned Tables.\n",
    "* Ability to write advanced SQL queries primarily using Analytic Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "Here is the exercise related to getting started module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Loading Data\n",
    "\n",
    "As part of this exercise, you need to take care of loading data using `COPY` Command.\n",
    "* You can connect to the database using following details in the environment provided by us.\n",
    "  * Host: localhost\n",
    "  * Port: 5342\n",
    "  * Database Name: YOUR_OS_USER_hr_db\n",
    "  * User Name: YOUR_OS_USER_hr_user\n",
    "  * Password: YOUR_OS_USER_PASSWORD (provided by us).\n",
    "* If you are using your own environment, make sure to create database for storing HR Data.\n",
    "  * Database Name: hr_db\n",
    "  * User Name: hr_user\n",
    "  * You can create user with password of your choice.\n",
    "  \n",
    "```sql\n",
    "CREATE DATABASE hr_db;\n",
    "CREATE USER hr_user WITH PASSWORD 'hr_password';\n",
    "GRANT ALL ON DATABASE hr_db TO hr_user;\n",
    "GRANT pg_read_server_files TO hr_user;\n",
    "```\n",
    "\n",
    "* Create table using this script.\n",
    "\n",
    "```sql\n",
    "CREATE TABLE employees\n",
    "   ( employee_id INTEGER\n",
    "   , first_name VARCHAR(20)\n",
    "   , last_name VARCHAR(25)\n",
    "   , email VARCHAR(25)\n",
    "   , phone_number VARCHAR(20)\n",
    "   , hire_date DATE\n",
    "   , job_id VARCHAR(10)\n",
    "   , salary NUMERIC(8,2)\n",
    "   , commission_pct NUMERIC(2,2)\n",
    "   , manager_id INTEGER\n",
    "   , department_id INTEGER\n",
    "   ) ;\n",
    "CREATE UNIQUE INDEX emp_emp_id_pk\n",
    "         ON employees (employee_id) ;\n",
    "ALTER TABLE employees ADD\n",
    "   PRIMARY KEY (employee_id);\n",
    "```\n",
    "\n",
    "* Understand data.\n",
    "  * Check for delimiters (record as well as field).\n",
    "  * Check whether header exists or not.\n",
    "  * Ensure number of fields for the table and data being loaded are same or not.\n",
    "* Load data into the table using `COPY` Command.\n",
    "* Validate by running these queries. You can also use SQL Workbench to run the queries to validate whether data is loaded successfully or not.\n",
    "\n",
    "```sql\n",
    "SELECT * FROM employees LIMIT 10;\n",
    "SELECT count(1) FROM employees;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DML or CRUD Operations\n",
    "\n",
    "Let's create a table and perform database operations using direct SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/pqtKUUI5cCo?rel=0&amp;controls=1&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/pqtKUUI5cCo?rel=0&amp;controls=1&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 - Create Table\n",
    "\n",
    "Create table - **courses**\n",
    "* course_id - sequence generated integer and primary key\n",
    "* course_name - which holds alpha numeric or string values up to 60 characters\n",
    "* course_author - which holds the name of the author up to 40 characters\n",
    "* course_status - which holds one of these values (published, draft, inactive). \n",
    "* course_published_dt - which holds date type value. \n",
    "\n",
    "Provide the script as answer for this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 - Inserting Data\n",
    "\n",
    "* Insert data into courses using the data provided. Make sure id is system generated.\n",
    "\n",
    "|Course Name                      |Course Author         |Course Status|Course Published Date|\n",
    "|---------------------------------|----------------------|-------------|---------------------|\n",
    "|Programming using Python         |Bob Dillon            |published    |2020-09-30           |\n",
    "|Data Engineering using Python    |Bob Dillon            |published    |2020-07-15           |\n",
    "|Data Engineering using Scala     |Elvis Presley         |draft        |                     |\n",
    "|Programming using Scala          |Elvis Presley         |published    |2020-05-12           |\n",
    "|Programming using Java           |Mike Jack             |inactive     |2020-08-10           |\n",
    "|Web Applications - Python Flask  |Bob Dillon            |inactive     |2020-07-20           |\n",
    "|Web Applications - Java Spring   |Mike Jack             |draft        |                     |\n",
    "|Pipeline Orchestration - Python  |Bob Dillon            |draft        |                     |\n",
    "|Streaming Pipelines - Python     |Bob Dillon            |published    |2020-10-05           |\n",
    "|Web Applications - Scala Play    |Elvis Presley         |inactive     |2020-09-30           |\n",
    "|Web Applications - Python Django |Bob Dillon            |published    |2020-06-23           |\n",
    "|Server Automation - Ansible      |Uncle Sam             |published    |2020-07-05           |\n",
    "\n",
    "Provide the insert statement(s) as answer for this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3 - Updating Data\n",
    "\n",
    "Update the status of all the **draft courses** related to Python and Scala to **published** along with the **course_published_dt using system date**. \n",
    "\n",
    "Provide the update statement as answer for this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4 - Deleting Data\n",
    "\n",
    "Delete all the courses which are neither in draft mode nor published.\n",
    "\n",
    "Provide the delete statement as answer for this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation - Get count of all published courses by author and make sure output is sorted in descending order by count. \n",
    "\n",
    "```sql\n",
    "SELECT course_author, count(1) AS course_count\n",
    "FROM courses\n",
    "WHERE course_status= 'published'\n",
    "GROUP BY course_author\n",
    "```\n",
    "\n",
    "|Course Author   |Course Count|\n",
    "|----------------|------------|\n",
    "|Bob Dillon      |5           |\n",
    "|Elvis Presley   |2           |\n",
    "|Uncle Sam       |1           |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic SQL Queries\n",
    "\n",
    "Here are some of the exercises for which you can write SQL queries to self evaluate.\n",
    "\n",
    "* Ensure that we have required database and user for retail data. **We might provide the database as part of our labs.** Here are the instructions to use `psql` for setting up the required database (if required) and tables.\n",
    "\n",
    "```shell\n",
    "psql -U postgres -h localhost -p 5432 -W\n",
    "```\n",
    "\n",
    "```sql\n",
    "CREATE DATABASE itversity_retail_db;\n",
    "CREATE USER itversity_retail_user WITH ENCRYPTED PASSWORD 'retail_password';\n",
    "GRANT ALL ON DATABASE itversity_retail_db TO itversity_retail_user;\n",
    "```\n",
    "\n",
    "* Create Tables using the script provided. You can either use `psql` or **SQL Workbench**.\n",
    "\n",
    "```shell\n",
    "psql -U itversity_retail_user \\\n",
    "  -h localhost \\\n",
    "  -p 5432 \\\n",
    "  -d itversity_retail_db \\\n",
    "  -W\n",
    "```\n",
    "\n",
    "* You can drop the existing tables.\n",
    "\n",
    "```sql\n",
    "DROP TABLE order_items;\n",
    "DROP TABLE orders;\n",
    "DROP TABLE customers;\n",
    "DROP TABLE products;\n",
    "DROP TABLE categories;\n",
    "DROP TABLE departments;\n",
    "```\n",
    "\n",
    "* Once the tables are dropped you can run below script to create the tables for the purpose of exercises.\n",
    "\n",
    "```sql\n",
    "\\i /data/retail_db/create_db_tables_pg.sql\n",
    "```\n",
    "\n",
    "* Data shall be loaded using the script provided.\n",
    "\n",
    "```sql\n",
    "\\i /data/retail_db/load_db_tables_pg.sql\n",
    "```\n",
    "\n",
    "* Run queries to validate we have data in all the 3 tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 - Customer order count\n",
    "\n",
    "Get order count per customer for the month of 2014 January.\n",
    "* Tables - orders and customers\n",
    "* Data should be sorted in descending order by count and ascending order by customer id.\n",
    "* Output should contain customer_id, customer_first_name, customer_last_name and customer_order_count."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 - Dormant Customers\n",
    "\n",
    "Get the customer details who have not placed any order for the month of 2014 January.\n",
    "* Tables - orders and customers\n",
    "* Data should be sorted in ascending order by customer_id\n",
    "* Output should contain all the fields from customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3 - Revenue Per Customer\n",
    "\n",
    "Get the revenue generated by each customer for the month of 2014 January\n",
    "* Tables - orders, order_items and customers\n",
    "* Data should be sorted in descending order by revenue and then ascending order by customer_id\n",
    "* Output should contain customer_id, customer_first_name, customer_last_name, customer_revenue.\n",
    "* If there are no orders placed by customer, then the corresponding revenue for a give customer should be 0.\n",
    "* Consider only COMPLETE and CLOSED orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4 - Revenue Per Category\n",
    "\n",
    "Get the revenue generated for each category for the month of 2014 January\n",
    "* Tables - orders, order_items, products and categories\n",
    "* Data should be sorted in ascending order by category_id.\n",
    "* Output should contain all the fields from category along with the revenue as category_revenue.\n",
    "* Consider only COMPLETE and CLOSED orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5 - Product Count Per Department\n",
    "\n",
    "Get the products for each department.\n",
    "* Tables - departments, categories, products\n",
    "* Data should be sorted in ascending order by department_id\n",
    "* Output should contain all the fields from department and the product count as product_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing Database Objects\n",
    "\n",
    "This exercise is primarily to assess your capabilities related to put all important DDL concepts in practice by coming up with solution for a typical data migration problem from one database (mysql) to another (postgres).\n",
    "* Here are the high level steps for database migration from one type of database to another type of database.\n",
    "  * Extract DDL Statements from source database (MySQL).\n",
    "  * Extract the data in the form of delimited files and ship them to target database.\n",
    "  * Refactor scripts as per target database (Postgres).\n",
    "  * Create tables in the target database.\n",
    "  * Execute pre-migration steps (disable constraints, drop indexes etc).\n",
    "  * Load the data using native utilities.\n",
    "  * Execute post-migration steps (enable constraints, create or rebuild indexes, reset sequences etc).\n",
    "  * Sanity checks with basic queries.\n",
    "  * Make sure all the impacted applications are validated thoroughly.\n",
    "* We have scripts and data set available in our GitHub repository. If you are using our environment the repository is already cloned under **/data/retail_db**.\n",
    "* It have scripts to create tables with primary keys. Those scripts are generated from MySQL tables and refactored for Postgres.\n",
    "  * Script to create tables: **create_db_tables_pg.sql**\n",
    "  * Load data into tables: **load_db_tables_pg.sql**\n",
    "* Here are the steps you need to perform to take care of this exercise.\n",
    "  * Create tables\n",
    "  * Load data\n",
    "  * All the tables have surrogate primary keys. Here are the details.\n",
    "    * orders.order_id\n",
    "    * order_items.order_item_id\n",
    "    * customers.customer_id\n",
    "    * products.product_id\n",
    "    * categories.category_id\n",
    "    * departments.department_id\n",
    "  * Get the maximum value from all surrogate primary key fields.\n",
    "  * Create sequences for all surrogate primary key fields using maximum value. Make sure to use standard naming conventions for sequences.\n",
    "  * Ensure sequences are mapped to the surrogate primary key fields.\n",
    "  * Create foreign key constraints based up on this information.\n",
    "    * orders.order_customer_id to customers.customer_id\n",
    "    * order_items.order_item_order_id to orders.order_id\n",
    "    * order_items.order_item_product_id to products.product_id\n",
    "    * products.product_category_id to categories.category_id\n",
    "    * categories.category_department_id to departments.department_id\n",
    "  * Insert few records in `departments` to ensure that sequence generated numbers are used for `department_id`.\n",
    "* Here are the commands to launch `psql` and run scripts to create tables as well as load data into tables.\n",
    "\n",
    "```sql\n",
    "psql -U itversity_retail_user \\\n",
    "  -h localhost \\\n",
    "  -p 5432 \\\n",
    "  -d itversity_retail_db \\\n",
    "  -W\n",
    "\n",
    "\\i /data/retail_db/create_db_tables_pg.sql\n",
    "\n",
    "\\i /data/retail_db/load_db_tables_pg.sql\n",
    "```\n",
    "* We use this approach of creating tables, loading data and then adding constraints as well as resetting sequences for large volume data migrations from one database to another database.\n",
    "* Here are the commands or queries you need to come up with to solve this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Queries to get maximum values from surrogate primary keys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Commands to add sequences with `START WITH` pointing to the maximum value for the corresponding surrogate primary key fields. Make sure to use meaningful names to sequences **TABLENAME_SURROGATEFIELD_seq** (example: users_user_id_seq for users.user_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Commands to alter sequences to bind them to corresponding surrogate primary key fields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Commands to add foreign key constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "Queries to validate whether constraints are created or not. You can come up with queries against `information_schema` tables such as `columns`, `sequences` etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partitioning Tables\n",
    "\n",
    "Here is the exercise to get comfort with partitioning. We will be using range partitioning.\n",
    "* Use retail database. Make sure **orders** table already exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/uAkrpaJmbx0?rel=0&amp;controls=1&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/uAkrpaJmbx0?rel=0&amp;controls=1&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Create table **orders_part** with the same columns as orders.\n",
    "* Partition the table by month using range partitioning on **order_date**.\n",
    "* Add 14 partitions - 13 based up on the data and 1 default. Here is the naming convention.\n",
    "  * Default - orders_part_default\n",
    "  * Partition for 2014 January - orders_part_201401"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Let us load and validate data in the partitioned table.\n",
    "* Load the data from **orders** into **orders_part**.\n",
    "* Get count on **orders_part** as well as all the 14 partitions. You should get 0 for default partition and all the records should be distributed using the other 13 partitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Defined Functions\n",
    "\n",
    "Here are the exercises to ensure our understanding related to Pre-Defined Functions.\n",
    "* We will use **users** table as well as other tables we got as part of retail database.\n",
    "* Information will be provided with each exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env DATABASE_URL=postgresql://itversity_retail_user:retail_password@localhost:5432/itversity_retail_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "DROP TABLE IF EXISTS users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "CREATE TABLE users(\n",
    "    user_id SERIAL PRIMARY KEY,\n",
    "    user_first_name VARCHAR(30),\n",
    "    user_last_name VARCHAR(30),\n",
    "    user_email_id VARCHAR(50),\n",
    "    user_gender VARCHAR(1),\n",
    "    user_unique_id VARCHAR(15),\n",
    "    user_phone_no VARCHAR(20),\n",
    "    user_dob DATE,\n",
    "    created_ts TIMESTAMP\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "insert into users (\n",
    "    user_first_name, user_last_name, user_email_id, user_gender, \n",
    "    user_unique_id, user_phone_no, user_dob, created_ts\n",
    ") VALUES\n",
    "    ('Giuseppe', 'Bode', 'gbode0@imgur.com', 'M', '88833-8759', \n",
    "     '+86 (764) 443-1967', '1973-05-31', '2018-04-15 12:13:38'),\n",
    "    ('Lexy', 'Gisbey', 'lgisbey1@mail.ru', 'F', '262501-029', \n",
    "     '+86 (751) 160-3742', '2003-05-31', '2020-12-29 06:44:09'),\n",
    "    ('Karel', 'Claringbold', 'kclaringbold2@yale.edu', 'F', '391-33-2823', \n",
    "     '+62 (445) 471-2682', '1985-11-28', '2018-11-19 00:04:08'),\n",
    "    ('Marv', 'Tanswill', 'mtanswill3@dedecms.com', 'F', '1195413-80', \n",
    "     '+62 (497) 736-6802', '1998-05-24', '2018-11-19 16:29:43'),\n",
    "    ('Gertie', 'Espinoza', 'gespinoza4@nationalgeographic.com', 'M', '471-24-6869', \n",
    "     '+249 (687) 506-2960', '1997-10-30', '2020-01-25 21:31:10'),\n",
    "    ('Saleem', 'Danneil', 'sdanneil5@guardian.co.uk', 'F', '192374-933', \n",
    "     '+63 (810) 321-0331', '1992-03-08', '2020-11-07 19:01:14'),\n",
    "    ('Rickert', 'O''Shiels', 'roshiels6@wikispaces.com', 'M', '749-27-47-52', \n",
    "     '+86 (184) 759-3933', '1972-11-01', '2018-03-20 10:53:24'),\n",
    "    ('Cybil', 'Lissimore', 'clissimore7@pinterest.com', 'M', '461-75-4198', \n",
    "     '+54 (613) 939-6976', '1978-03-03', '2019-12-09 14:08:30'),\n",
    "    ('Melita', 'Rimington', 'mrimington8@mozilla.org', 'F', '892-36-676-2', \n",
    "     '+48 (322) 829-8638', '1995-12-15', '2018-04-03 04:21:33'),\n",
    "    ('Benetta', 'Nana', 'bnana9@google.com', 'M', '197-54-1646', \n",
    "     '+420 (934) 611-0020', '1971-12-07', '2018-10-17 21:02:51'),\n",
    "    ('Gregorius', 'Gullane', 'ggullanea@prnewswire.com', 'F', '232-55-52-58', \n",
    "     '+62 (780) 859-1578', '1973-09-18', '2020-01-14 23:38:53'),\n",
    "    ('Una', 'Glayzer', 'uglayzerb@pinterest.com', 'M', '898-84-336-6', \n",
    "     '+380 (840) 437-3981', '1983-05-26', '2019-09-17 03:24:21'),\n",
    "    ('Jamie', 'Vosper', 'jvosperc@umich.edu', 'M', '247-95-68-44', \n",
    "     '+81 (205) 723-1942', '1972-03-18', '2020-07-23 16:39:33'),\n",
    "    ('Calley', 'Tilson', 'ctilsond@issuu.com', 'F', '415-48-894-3', \n",
    "     '+229 (698) 777-4904', '1987-06-12', '2020-06-05 12:10:50'),\n",
    "    ('Peadar', 'Gregorowicz', 'pgregorowicze@omniture.com', 'M', '403-39-5-869', \n",
    "     '+7 (267) 853-3262', '1996-09-21', '2018-05-29 23:51:31'),\n",
    "    ('Jeanie', 'Webling', 'jweblingf@booking.com', 'F', '399-83-05-03', \n",
    "     '+351 (684) 413-0550', '1994-12-27', '2018-02-09 01:31:11'),\n",
    "    ('Yankee', 'Jelf', 'yjelfg@wufoo.com', 'F', '607-99-0411', \n",
    "     '+1 (864) 112-7432', '1988-11-13', '2019-09-16 16:09:12'),\n",
    "    ('Blair', 'Aumerle', 'baumerleh@toplist.cz', 'F', '430-01-578-5', \n",
    "     '+7 (393) 232-1860', '1979-11-09', '2018-10-28 19:25:35'),\n",
    "    ('Pavlov', 'Steljes', 'psteljesi@macromedia.com', 'F', '571-09-6181', \n",
    "     '+598 (877) 881-3236', '1991-06-24', '2020-09-18 05:34:31'),\n",
    "    ('Darn', 'Hadeke', 'dhadekej@last.fm', 'M', '478-32-02-87', \n",
    "     '+370 (347) 110-4270', '1984-09-04', '2018-02-10 12:56:00'),\n",
    "    ('Wendell', 'Spanton', 'wspantonk@de.vu', 'F', null, \n",
    "     '+84 (301) 762-1316', '1973-07-24', '2018-01-30 01:20:11'),\n",
    "    ('Carlo', 'Yearby', 'cyearbyl@comcast.net', 'F', null, \n",
    "     '+55 (288) 623-4067', '1974-11-11', '2018-06-24 03:18:40'),\n",
    "    ('Sheila', 'Evitts', 'sevittsm@webmd.com', null, '830-40-5287',\n",
    "     null, '1977-03-01', '2020-07-20 09:59:41'),\n",
    "    ('Sianna', 'Lowdham', 'slowdhamn@stanford.edu', null, '778-0845', \n",
    "     null, '1985-12-23', '2018-06-29 02:42:49'),\n",
    "    ('Phylys', 'Aslie', 'paslieo@qq.com', 'M', '368-44-4478', \n",
    "     '+86 (765) 152-8654', '1984-03-22', '2019-10-01 01:34:28')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Get all the number of users created per year.\n",
    "* Use **users** table for this exercise.\n",
    "* Output should contain 4 digit year and count.\n",
    "* Use date specific functions to get the year using created_ts.\n",
    "* Make sure you define aliases to the columns as **created_year** and **user_count** respectively.\n",
    "* Data should be sorted in ascending order by **created_year**.\n",
    "* When you run the query using Jupyter environment, it might have decimals for integers. Hence you can display results even with decimal points.\n",
    "* Here is the sample output.\n",
    "\n",
    "|created_year|user_count|\n",
    "|----|--|\n",
    "|2018|13|\n",
    "|2019|4|\n",
    "|2020|8|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Get the day name of the birth days for all the users born in the month of June.\n",
    "* Use **users** table for this exercise.\n",
    "* Output should contain user_id, user_dob, user_email_id and user_day_of_birth.\n",
    "* Use date specific functions to get the month using user_dob.\n",
    "* **user_day_of_birth** should be full day with first character in upper case such as **Tuesday**\n",
    "* Data should be sorted by day with in the month of May.\n",
    "\n",
    "|user_id|user_dob|user_email_id|user_day_of_birth|\n",
    "|-|----------|----------------------|------|\n",
    "|4|1998-05-24|mtanswill3@dedecms.com|Sunday|\n",
    "|12|1983-05-26|uglayzerb@pinterest.com|Thursday|\n",
    "|1|1973-05-31|gbode0@imgur.com|Thursday|\n",
    "|2|2003-05-31|lgisbey1@mail.ru|Saturday|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Get the names and email ids of users added in year 2019.\n",
    "\n",
    "* Use **users** table for this exercise.\n",
    "* Output should contain user_id, user_name, user_email_id, created_ts, created_year.\n",
    "* Use date specific functions to get the year using created_ts.\n",
    "* **user_name** is a derived column by concatenating user_first_name and user_last_name with space in between.\n",
    "* **user_name** should have values in upper case.\n",
    "* Data should be sorted in ascending order by user_name\n",
    "\n",
    "|user_id|user_name|user_email_id|created_ts|created_year|\n",
    "|-|---------|------|------|------|\n",
    "|8|CYBIL LISSIMORE|clissimore7@pinterest.com|2019-12-09 14:08:30|2019.0|\n",
    "|25|PHYLYS ASLIE|paslieo@qq.com|2019-10-01 01:34:28|2019.0|\n",
    "|12|UNA GLAYZER|uglayzerb@pinterest.com|2019-09-17 03:24:21|2019.0|\n",
    "|17|YANKEE JELF|yjelfg@wufoo.com|2019-09-16 16:09:12|2019.0|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Get the number of users by gender.\n",
    "\n",
    "* Use **users** table for this exercise.\n",
    "* Output should contain gender and user_count.\n",
    "* For males the output should display **Male** and for females the output should display **Female**.\n",
    "* If gender is not specified, then it should display **Not Specified**.\n",
    "* Data should be sorted in descending order by user_count.\n",
    "\n",
    "|user_gender|user_count|\n",
    "|----|--|\n",
    "|Female|13|\n",
    "|Male|10|\n",
    "|Not Specified|2|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "Get last 4 digits of unique ids.\n",
    "\n",
    "* Use **users** table for this exercise.\n",
    "* Output should contain user_id, user_unique_id and user_unique_id_last4\n",
    "* Unique ids are either null or not null.\n",
    "* Unique ids contain numbers and hyphens and are of different length.\n",
    "* We need to get last 4 digits discarding hyphens only when the number of digits are at least 9.\n",
    "* If unique id is null, then you should dispaly **Not Specified**.\n",
    "* After discarding hyphens, if unique id have less than 9 digits then you should display **Invalid Unique Id**.\n",
    "* Data should be sorted by user_id. You might see **None** or **null** for those user ids where there is no unique id for **user_unique_id**\n",
    "\n",
    "|user_id|user_unique_id|user_unique_id_last4|\n",
    "|-|----|----|\n",
    "|1|88833-8759|8759|\n",
    "|2|262501-029|1029|\n",
    "|3|391-33-2823|2823|\n",
    "|4|1195413-80|1380|\n",
    "|5|471-24-6869|6869|\n",
    "|6|192374-933|4933|\n",
    "|7|749-27-47-52|4752|\n",
    "|8|461-75-4198|4198|\n",
    "|9|892-36-676-2|6762|\n",
    "|10|197-54-1646|1646|\n",
    "|11|232-55-52-58|5258|\n",
    "|12|898-84-336-6|3366|\n",
    "|13|247-95-68-44|6844|\n",
    "|14|415-48-894-3|8943|\n",
    "|15|403-39-5-869|5869|\n",
    "|16|399-83-05-03|0503|\n",
    "|17|607-99-0411|0411|\n",
    "|18|430-01-578-5|5785|\n",
    "|19|571-09-6181|6181|\n",
    "|20|478-32-02-87|0287|\n",
    "|21||Not Specified|\n",
    "|22||Not Specified|\n",
    "|23|830-40-5287|5287|\n",
    "|24|778-0845|Invalid Unique Id|\n",
    "|25|368-44-4478|4478|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "Get the count of users based up on country code.\n",
    "\n",
    "* Use users table for this exercise.\n",
    "* Output should contain country code and count.\n",
    "* There should be no `+` in the country code. It should only contain digits.\n",
    "* Data should be sorted as numbers by country code.\n",
    "* We should discard user_phone_no with null values.\n",
    "* Here is the desired output:\n",
    "\n",
    "|country_code|user_count|\n",
    "|-|-|\n",
    "|1|1|\n",
    "|7|2|\n",
    "|48|1|\n",
    "|54|1|\n",
    "|55|1|\n",
    "|62|3|\n",
    "|63|1|\n",
    "|81|1|\n",
    "|84|1|\n",
    "|86|4|\n",
    "|229|1|\n",
    "|249|1|\n",
    "|351|1|\n",
    "|370|1|\n",
    "|380|1|\n",
    "|420|1|\n",
    "|598|1|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "\n",
    "Let us validate if we have invalid **order_item_subtotal** as part of **order_items** table.\n",
    "\n",
    "* **order_items** table have 6 fields.\n",
    "  * order_item_id\n",
    "  * order_item_order_id\n",
    "  * order_item_product_id\n",
    "  * order_item_quantity\n",
    "  * order_item_subtotal\n",
    "  * order_item_product_price\n",
    "* **order_item_subtotal** is nothing but product of **order_item_quantity** and **order_item_product_price**. It means order_item_subtotal is compute by multiplying order_item_quantity and order_item_product_price for each item.\n",
    "* You need to get the count of order_items where **order_item_subtotal** is not equal to the product of **order_item_quantity** and **order_item_product_price**.\n",
    "* There can be issues related to rounding off. Make sure it is taken care using appropriate function.\n",
    "* Output should be 0 as there are no such records.\n",
    "\n",
    "|count|\n",
    "|-|\n",
    "|0|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8\n",
    "\n",
    "Get number of orders placed on weekdays and weekends in the month of January 2014.\n",
    "\n",
    "* **orders** have 4 fields\n",
    "  * order_id\n",
    "  * order_date\n",
    "  * order_customer_id\n",
    "  * order_status\n",
    "* Use order date to determine the day on which orders are placed.\n",
    "* Output should contain 2 columns - day_type and order_count.\n",
    "* **day_type** should have 2 values **Week days** and **Weekend days**.\n",
    "* Here is the desired output.\n",
    "\n",
    "|day_type|order_count|\n",
    "|-|-|\n",
    "|Weekend days|1505|\n",
    "|Week days|4403|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analytics Functions\n",
    "\n",
    "Let us take care of the exercises related to analytics functions. We will be using HR database for the same.\n",
    "\n",
    "* Get all the employees who is making more than average salary with in each department.\n",
    "* Get cumulative salary for one of the department along with department name.\n",
    "* Get top 3 paid employees with in each department by salary (use dense_rank)\n",
    "* Get top 3 products sold in the month of 2014 January by revenue.\n",
    "* Get top 3 products in each category sold in the month of 2014 January by revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare HR Database\n",
    "\n",
    "Here are the steps to prepare HR database.\n",
    "* Connect to HR DB using `psql` or SQL Workbench. Here is the sample `psql` command.\n",
    "\n",
    "```shell\n",
    "psql -h localhost \\\n",
    "    -p 5432 \\\n",
    "    -d itversity_hr_db \\\n",
    "    -U itversity_hr_user \\\n",
    "    -W\n",
    "```\n",
    "\n",
    "* Run scripts to create tables and load the data. You can also drop the tables if they already exists.\n",
    "\n",
    "```sql\n",
    "\\i /data/hr_db/drop_tables_pg.sql\n",
    "\\i /data/hr_db/create_tables_pg.sql\n",
    "\\i /data/hr_db/load_tables_pg.sql\n",
    "```\n",
    "\n",
    "* Validate to ensure that data is available in the tables by running these queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Retail Database\n",
    "\n",
    "Make sure to drop and recreate the tables before taking care of the exercises related to retail database.\n",
    "\n",
    "* Ensure that we have required database and user for retail data. **We might provide the database as part of our labs.** Here are the instructions to use `psql` for setting up the required database (if required) and tables.\n",
    "\n",
    "```shell\n",
    "psql -U postgres -h localhost -p 5432 -W\n",
    "```\n",
    "\n",
    "```sql\n",
    "CREATE DATABASE itversity_retail_db;\n",
    "CREATE USER itversity_retail_user WITH ENCRYPTED PASSWORD 'retail_password';\n",
    "GRANT ALL ON DATABASE itversity_retail_db TO itversity_retail_user;\n",
    "```\n",
    "\n",
    "* Create Tables using the script provided. You can either use `psql` or **SQL Workbench**.\n",
    "\n",
    "```shell\n",
    "psql -U itversity_retail_user \\\n",
    "  -h localhost \\\n",
    "  -p 5432 \\\n",
    "  -d itversity_retail_db \\\n",
    "  -W\n",
    "```\n",
    "\n",
    "* You can drop the existing tables.\n",
    "\n",
    "```sql\n",
    "DROP TABLE order_items;\n",
    "DROP TABLE orders;\n",
    "DROP TABLE customers;\n",
    "DROP TABLE products;\n",
    "DROP TABLE categories;\n",
    "DROP TABLE departments;\n",
    "```\n",
    "\n",
    "* Once the tables are dropped you can run below script to create the tables for the purpose of exercises.\n",
    "\n",
    "```sql\n",
    "\\i /data/retail_db/create_db_tables_pg.sql\n",
    "```\n",
    "\n",
    "* Data shall be loaded using the script provided.\n",
    "\n",
    "```sql\n",
    "\\i /data/retail_db/load_db_tables_pg.sql\n",
    "```\n",
    "\n",
    "* Run queries to validate we have data in all the 3 tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DATABASE_URL=postgresql://itversity_hr_user:hr_password@localhost:5432/itversity_hr_db\n"
     ]
    }
   ],
   "source": [
    "%env DATABASE_URL=postgresql://itversity_hr_user:hr_password@localhost:5432/itversity_hr_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://itversity_hr_user:***@localhost:5432/itversity_hr_db\n",
      "10 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>employee_id</th>\n",
       "        <th>first_name</th>\n",
       "        <th>last_name</th>\n",
       "        <th>email</th>\n",
       "        <th>phone_number</th>\n",
       "        <th>hire_date</th>\n",
       "        <th>job_id</th>\n",
       "        <th>salary</th>\n",
       "        <th>commission_pct</th>\n",
       "        <th>manager_id</th>\n",
       "        <th>department_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>100</td>\n",
       "        <td>Steven</td>\n",
       "        <td>King</td>\n",
       "        <td>SKING</td>\n",
       "        <td>515.123.4567</td>\n",
       "        <td>1987-06-17</td>\n",
       "        <td>AD_PRES</td>\n",
       "        <td>24000.00</td>\n",
       "        <td>None</td>\n",
       "        <td>None</td>\n",
       "        <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>101</td>\n",
       "        <td>Neena</td>\n",
       "        <td>Kochhar</td>\n",
       "        <td>NKOCHHAR</td>\n",
       "        <td>515.123.4568</td>\n",
       "        <td>1989-09-21</td>\n",
       "        <td>AD_VP</td>\n",
       "        <td>17000.00</td>\n",
       "        <td>None</td>\n",
       "        <td>100</td>\n",
       "        <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>102</td>\n",
       "        <td>Lex</td>\n",
       "        <td>De Haan</td>\n",
       "        <td>LDEHAAN</td>\n",
       "        <td>515.123.4569</td>\n",
       "        <td>1993-01-13</td>\n",
       "        <td>AD_VP</td>\n",
       "        <td>17000.00</td>\n",
       "        <td>None</td>\n",
       "        <td>100</td>\n",
       "        <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>103</td>\n",
       "        <td>Alexander</td>\n",
       "        <td>Hunold</td>\n",
       "        <td>AHUNOLD</td>\n",
       "        <td>590.423.4567</td>\n",
       "        <td>1990-01-03</td>\n",
       "        <td>IT_PROG</td>\n",
       "        <td>9000.00</td>\n",
       "        <td>None</td>\n",
       "        <td>102</td>\n",
       "        <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>104</td>\n",
       "        <td>Bruce</td>\n",
       "        <td>Ernst</td>\n",
       "        <td>BERNST</td>\n",
       "        <td>590.423.4568</td>\n",
       "        <td>1991-05-21</td>\n",
       "        <td>IT_PROG</td>\n",
       "        <td>6000.00</td>\n",
       "        <td>None</td>\n",
       "        <td>103</td>\n",
       "        <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>105</td>\n",
       "        <td>David</td>\n",
       "        <td>Austin</td>\n",
       "        <td>DAUSTIN</td>\n",
       "        <td>590.423.4569</td>\n",
       "        <td>1997-06-25</td>\n",
       "        <td>IT_PROG</td>\n",
       "        <td>4800.00</td>\n",
       "        <td>None</td>\n",
       "        <td>103</td>\n",
       "        <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>106</td>\n",
       "        <td>Valli</td>\n",
       "        <td>Pataballa</td>\n",
       "        <td>VPATABAL</td>\n",
       "        <td>590.423.4560</td>\n",
       "        <td>1998-02-05</td>\n",
       "        <td>IT_PROG</td>\n",
       "        <td>4800.00</td>\n",
       "        <td>None</td>\n",
       "        <td>103</td>\n",
       "        <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>107</td>\n",
       "        <td>Diana</td>\n",
       "        <td>Lorentz</td>\n",
       "        <td>DLORENTZ</td>\n",
       "        <td>590.423.5567</td>\n",
       "        <td>1999-02-07</td>\n",
       "        <td>IT_PROG</td>\n",
       "        <td>4200.00</td>\n",
       "        <td>None</td>\n",
       "        <td>103</td>\n",
       "        <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>108</td>\n",
       "        <td>Nancy</td>\n",
       "        <td>Greenberg</td>\n",
       "        <td>NGREENBE</td>\n",
       "        <td>515.124.4569</td>\n",
       "        <td>1994-08-17</td>\n",
       "        <td>FI_MGR</td>\n",
       "        <td>12000.00</td>\n",
       "        <td>None</td>\n",
       "        <td>101</td>\n",
       "        <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>109</td>\n",
       "        <td>Daniel</td>\n",
       "        <td>Faviet</td>\n",
       "        <td>DFAVIET</td>\n",
       "        <td>515.124.4169</td>\n",
       "        <td>1994-08-16</td>\n",
       "        <td>FI_ACCOUNT</td>\n",
       "        <td>9000.00</td>\n",
       "        <td>None</td>\n",
       "        <td>108</td>\n",
       "        <td>100</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(100, 'Steven', 'King', 'SKING', '515.123.4567', datetime.date(1987, 6, 17), 'AD_PRES', Decimal('24000.00'), None, None, 90),\n",
       " (101, 'Neena', 'Kochhar', 'NKOCHHAR', '515.123.4568', datetime.date(1989, 9, 21), 'AD_VP', Decimal('17000.00'), None, 100, 90),\n",
       " (102, 'Lex', 'De Haan', 'LDEHAAN', '515.123.4569', datetime.date(1993, 1, 13), 'AD_VP', Decimal('17000.00'), None, 100, 90),\n",
       " (103, 'Alexander', 'Hunold', 'AHUNOLD', '590.423.4567', datetime.date(1990, 1, 3), 'IT_PROG', Decimal('9000.00'), None, 102, 60),\n",
       " (104, 'Bruce', 'Ernst', 'BERNST', '590.423.4568', datetime.date(1991, 5, 21), 'IT_PROG', Decimal('6000.00'), None, 103, 60),\n",
       " (105, 'David', 'Austin', 'DAUSTIN', '590.423.4569', datetime.date(1997, 6, 25), 'IT_PROG', Decimal('4800.00'), None, 103, 60),\n",
       " (106, 'Valli', 'Pataballa', 'VPATABAL', '590.423.4560', datetime.date(1998, 2, 5), 'IT_PROG', Decimal('4800.00'), None, 103, 60),\n",
       " (107, 'Diana', 'Lorentz', 'DLORENTZ', '590.423.5567', datetime.date(1999, 2, 7), 'IT_PROG', Decimal('4200.00'), None, 103, 60),\n",
       " (108, 'Nancy', 'Greenberg', 'NGREENBE', '515.124.4569', datetime.date(1994, 8, 17), 'FI_MGR', Decimal('12000.00'), None, 101, 100),\n",
       " (109, 'Daniel', 'Faviet', 'DFAVIET', '515.124.4169', datetime.date(1994, 8, 16), 'FI_ACCOUNT', Decimal('9000.00'), None, 108, 100)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT * FROM employees LIMIT 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://itversity_hr_user:***@localhost:5432/itversity_hr_db\n",
      "10 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>department_id</th>\n",
       "        <th>department_name</th>\n",
       "        <th>manager_id</th>\n",
       "        <th>location_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>90</td>\n",
       "        <td>Executive</td>\n",
       "        <td>100</td>\n",
       "        <td>1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>60</td>\n",
       "        <td>IT</td>\n",
       "        <td>103</td>\n",
       "        <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>100</td>\n",
       "        <td>Finance</td>\n",
       "        <td>108</td>\n",
       "        <td>1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>30</td>\n",
       "        <td>Purchasing</td>\n",
       "        <td>114</td>\n",
       "        <td>1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>50</td>\n",
       "        <td>Shipping</td>\n",
       "        <td>121</td>\n",
       "        <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>80</td>\n",
       "        <td>Sales</td>\n",
       "        <td>145</td>\n",
       "        <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>10</td>\n",
       "        <td>Administration</td>\n",
       "        <td>200</td>\n",
       "        <td>1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>20</td>\n",
       "        <td>Marketing</td>\n",
       "        <td>201</td>\n",
       "        <td>1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>40</td>\n",
       "        <td>Human Resources</td>\n",
       "        <td>203</td>\n",
       "        <td>2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>70</td>\n",
       "        <td>Public Relations</td>\n",
       "        <td>204</td>\n",
       "        <td>2700</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(90, 'Executive', 100, 1700),\n",
       " (60, 'IT', 103, 1400),\n",
       " (100, 'Finance', 108, 1700),\n",
       " (30, 'Purchasing', 114, 1700),\n",
       " (50, 'Shipping', 121, 1500),\n",
       " (80, 'Sales', 145, 2500),\n",
       " (10, 'Administration', 200, 1700),\n",
       " (20, 'Marketing', 201, 1800),\n",
       " (40, 'Human Resources', 203, 2400),\n",
       " (70, 'Public Relations', 204, 2700)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "\n",
    "SELECT * FROM departments \n",
    "ORDER BY manager_id NULLS LAST\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Get all the employees who is making more than average salary with in each department.\n",
    "\n",
    "* Use HR database employees and department tables for this problem.\n",
    "* Compute average salary expense for each department and get those employee details who are making more salary than average salary.\n",
    "* Make sure average salary expense per department is rounded off to 2 decimals.\n",
    "* Output should contain employee_id, department_name, salary and avg_salary_expense (derived field).\n",
    "* Data should be sorted in ascending order by department_id and descending order by salary.\n",
    "\n",
    "|employee_id|department_name|salary|avg_salary_expense|\n",
    "|---|---|---|---|\n",
    "|201|Marketing|13000.00|9500.00|\n",
    "|114|Purchasing|11000.00|4150.00|\n",
    "|121|Shipping|8200.00|3475.56|\n",
    "|120|Shipping|8000.00|3475.56|\n",
    "|122|Shipping|7900.00|3475.56|\n",
    "|123|Shipping|6500.00|3475.56|\n",
    "|124|Shipping|5800.00|3475.56|\n",
    "|184|Shipping|4200.00|3475.56|\n",
    "|185|Shipping|4100.00|3475.56|\n",
    "|192|Shipping|4000.00|3475.56|\n",
    "|193|Shipping|3900.00|3475.56|\n",
    "|188|Shipping|3800.00|3475.56|\n",
    "|137|Shipping|3600.00|3475.56|\n",
    "|189|Shipping|3600.00|3475.56|\n",
    "|141|Shipping|3500.00|3475.56|\n",
    "|103|IT|9000.00|5760.00|\n",
    "|104|IT|6000.00|5760.00|\n",
    "|145|Sales|14000.00|8955.88|\n",
    "|146|Sales|13500.00|8955.88|\n",
    "|147|Sales|12000.00|8955.88|\n",
    "|168|Sales|11500.00|8955.88|\n",
    "|148|Sales|11000.00|8955.88|\n",
    "|174|Sales|11000.00|8955.88|\n",
    "|149|Sales|10500.00|8955.88|\n",
    "|162|Sales|10500.00|8955.88|\n",
    "|156|Sales|10000.00|8955.88|\n",
    "|150|Sales|10000.00|8955.88|\n",
    "|169|Sales|10000.00|8955.88|\n",
    "|170|Sales|9600.00|8955.88|\n",
    "|163|Sales|9500.00|8955.88|\n",
    "|151|Sales|9500.00|8955.88|\n",
    "|157|Sales|9500.00|8955.88|\n",
    "|158|Sales|9000.00|8955.88|\n",
    "|152|Sales|9000.00|8955.88|\n",
    "|100|Executive|24000.00|19333.33|\n",
    "|108|Finance|12000.00|8600.00|\n",
    "|109|Finance|9000.00|8600.00|\n",
    "|205|Accounting|12000.00|10150.00|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DATABASE_URL=postgresql://itversity_hr_user:hr_password@localhost:5432/itversity_hr_db\n"
     ]
    }
   ],
   "source": [
    "%env DATABASE_URL=postgresql://itversity_hr_user:hr_password@localhost:5432/itversity_hr_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Get cumulative salary with in each department for Finance and IT department along with department name.\n",
    "\n",
    "* Use HR database employees and department tables for this problem.\n",
    "* Compute cumulative salary expense for **Finance** as well as **IT** departments with in respective departments.\n",
    "* Make sure cumulative salary expense per department is rounded off to 2 decimals.\n",
    "* Output should contain employee_id, department_name, salary and cum_salary_expense (derived field).\n",
    "* Data should be sorted in ascending order by department_name and then salary.\n",
    "\n",
    "|employee_id|department_name|salary|cum_salary_expense|\n",
    "|---|---|---|---|\n",
    "|113|Finance|6900.00|6900.00|\n",
    "|111|Finance|7700.00|14600.00|\n",
    "|112|Finance|7800.00|22400.00|\n",
    "|110|Finance|8200.00|30600.00|\n",
    "|109|Finance|9000.00|39600.00|\n",
    "|108|Finance|12000.00|51600.00|\n",
    "|107|IT|4200.00|4200.00|\n",
    "|106|IT|4800.00|9000.00|\n",
    "|105|IT|4800.00|13800.00|\n",
    "|104|IT|6000.00|19800.00|\n",
    "|103|IT|9000.00|28800.00|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Get top 3 paid employees with in each department by salary (use dense_rank)\n",
    "\n",
    "* Use HR database employees and department tables for this problem.\n",
    "* Highest paid employee should be ranked first.\n",
    "* Output should contain employee_id, department_id, department_name, salary and employee_rank (derived field).\n",
    "* Data should be sorted in ascending order by department_id in ascending order and then salary in descending order.\n",
    "\n",
    "|employee_id|department_id|department_name|salary|employee_rank|\n",
    "|---|---|---|---|---|\n",
    "|200|10|Administration|4400.00|1|\n",
    "|201|20|Marketing|13000.00|1|\n",
    "|202|20|Marketing|6000.00|2|\n",
    "|114|30|Purchasing|11000.00|1|\n",
    "|115|30|Purchasing|3100.00|2|\n",
    "|116|30|Purchasing|2900.00|3|\n",
    "|203|40|Human Resources|6500.00|1|\n",
    "|121|50|Shipping|8200.00|1|\n",
    "|120|50|Shipping|8000.00|2|\n",
    "|122|50|Shipping|7900.00|3|\n",
    "|103|60|IT|9000.00|1|\n",
    "|104|60|IT|6000.00|2|\n",
    "|105|60|IT|4800.00|3|\n",
    "|106|60|IT|4800.00|3|\n",
    "|204|70|Public Relations|10000.00|1|\n",
    "|145|80|Sales|14000.00|1|\n",
    "|146|80|Sales|13500.00|2|\n",
    "|147|80|Sales|12000.00|3|\n",
    "|100|90|Executive|24000.00|1|\n",
    "|101|90|Executive|17000.00|2|\n",
    "|102|90|Executive|17000.00|2|\n",
    "|108|100|Finance|12000.00|1|\n",
    "|109|100|Finance|9000.00|2|\n",
    "|110|100|Finance|8200.00|3|\n",
    "|205|110|Accounting|12000.00|1|\n",
    "|206|110|Accounting|8300.00|2|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Get top 3 products sold in the month of 2014 January by revenue.\n",
    "\n",
    "* Use retail database tables such as orders, order_items and products.\n",
    "* Highest revenue generating product should come at top.\n",
    "* Consider only those orders which are either in **COMPLETE** or **CLOSED** status.\n",
    "* Output should contain product_id, product_name, revenue, product_rank. **revenue** and **product_rank** are derived fields.\n",
    "* Data should be sorted in descending order by revenue.\n",
    "\n",
    "|product_id|product_name|revenue|product_rank|\n",
    "|---|---|---|---|\n",
    "|1004|Field & Stream Sportsman 16 Gun Fire Safe|250787.46|1|\n",
    "|365|Perfect Fitness Perfect Rip Deck|151474.75|2|\n",
    "|957|Diamondback Women's Serene Classic Comfort Bi|148190.12|3|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "Get top 3 products sold in the month of 2014 January under selected categories by revenue. The categories are **Cardio Equipment** and **Strength Training**.\n",
    "\n",
    "* Use retail database tables such as orders, order_items, products as well as categories.\n",
    "* Highest revenue generating product should come at top.\n",
    "* Consider only those orders which are either in **COMPLETE** or **CLOSED** status.\n",
    "* Output should contain category_id, category_name, product_id, product_name, revenue, product_rank. revenue and product_rank are derived fields.\n",
    "* Data should be sorted in ascending order by category_id and descending order by revenue.\n",
    "\n",
    "|category_id|category_name|product_id|product_name|revenue|product_rank|\n",
    "|---|---|---|---|---|---|\n",
    "|9|Cardio Equipment|191|Nike Men's Free 5.0+ Running Shoe|132286.77|1|\n",
    "|9|Cardio Equipment|172|Nike Women's Tempo Shorts|870.00|2|\n",
    "|10|Strength Training|208|SOLE E35 Elliptical|1999.99|1|\n",
    "|10|Strength Training|203|GoPro HERO3+ Black Edition Camera|1199.97|2|\n",
    "|10|Strength Training|216|Yakima DoubleDown Ace Hitch Mount 4-Bike Rack|189.00|3|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
